{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29476e1d",
   "metadata": {},
   "source": [
    "# Phase computation for pulsar using PINT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69ed96d",
   "metadata": {},
   "source": [
    "This notebook has been done for the following version of Gammapy and PINT:\n",
    "\n",
    "Gammapy version : 1.2\n",
    "\n",
    "PINT version : 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a30dd7",
   "metadata": {},
   "source": [
    "This notebook shows how to compute and add the phase information into the events files of pulsar observations. This step is needed to perform the pulsar analysis with Gammapy and should be the first step in the high level analysis. For the pulsar analysis we need two ingredients:\n",
    "\n",
    "1. The time of arrivals (TOAs). These times should have very high precision due to the common fast periods of pulsars. Usually these times are already stored in the EventList. For the computation of pulsar timing, times must be corrected in order to be referenced in the Solar System barycenter (SSB) because this system can nearly be regarded as an inertial reference frame with respect to the pulsar.\n",
    "\n",
    "\n",
    "2. The model of rotation of the pulsar, also known as ephemeris, at the epoch of the observations. These ephemerides are stored in a specific format and saved as .par files which contain the periods, derivatives of the periods, coordinates, glitches, etc.\n",
    "\n",
    "__For the following steps of this tutorial, we need the original EventLists from the DL3 files, and a model in .par format.__\n",
    "\n",
    "The main software that we will use to make the barycentric corrections and the phase-folding to the model is the PINT python library, [Luo J., Ransom S. et al., 2021](https://arxiv.org/abs/2012.00074), [ASCL](http://ascl.net/1902.007).\n",
    "For more information about this package, see [PINT documentation](https://nanograv-pint.readthedocs.io/en/latest/). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61c515c",
   "metadata": {},
   "source": [
    "## 0. Dependencies and imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c72d26",
   "metadata": {},
   "source": [
    "To run this notebook, you must have Gammapy and PINT (see documentation above) installed in the same environment. We recommend installing Gammapy first and then installing PINT using your preferred package manager.\n",
    "\n",
    "\n",
    "`$ conda env create -n gammapy-pint -f gammapy-pint-environment.yml`\n",
    "\n",
    "`$ conda activate gammapy-pint`\n",
    "\n",
    "`$ pip install pint-pulsar`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2329c197",
   "metadata": {},
   "source": [
    "Alternatively, one can also run the yaml environement file provided in the folder of this notebook:\n",
    "\n",
    "`$ conda env create -n gammapy-pint -f gammapy-pint-environment.yml`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68d2444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gammapy\n",
    "import pint\n",
    "\n",
    "print(f\"Gammapy version : {gammapy.__version__}\")\n",
    "print(f\"PINT version : {pint.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61b5e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.units as u\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import SkyCoord\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from gammapy.data import DataStore, EventList, Observation\n",
    "import logging\n",
    "\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ae3a58",
   "metadata": {},
   "source": [
    "We also need some imports from PINT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ac4aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pint.models as pmodels\n",
    "from pint import toa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aae5f4b",
   "metadata": {},
   "source": [
    "## 1. Reading DataStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b486ec45",
   "metadata": {},
   "source": [
    "First we need to define the data sample. In this notebook we will use two runs from the MAGIC gammapy data sample available in https://github.com/gammapy/gammapy-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e182bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the DL3 data\n",
    "DL3_dir = \"$GAMMAPY_DATA/magic/rad_max/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5019a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read DataStore from a directory\n",
    "data_store = DataStore.from_dir(DL3_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b551325a",
   "metadata": {},
   "source": [
    "Let's run this tutorial for the Crab pulsar :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba16fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pos = SkyCoord(ra=083.633, dec=+22.014, unit=\"deg\", frame=\"icrs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bda835",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = dict(\n",
    "    type=\"sky_circle\",\n",
    "    frame=\"icrs\",\n",
    "    lon=target_pos.ra,\n",
    "    lat=target_pos.dec,\n",
    "    radius=\"5 deg\",\n",
    ")\n",
    "selected_obs_table = data_store.obs_table.select_observations(selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96ccf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_id = selected_obs_table[\"OBS_ID\"]\n",
    "print(obs_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b77aaae",
   "metadata": {},
   "source": [
    "For the following we will take the run 5029747."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6e36d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = data_store.get_observations(\n",
    "    [5029747], required_irf=\"point-like\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec2c1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd88876",
   "metadata": {},
   "source": [
    "## 2. Phase-folding with PINT for one observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162a3ac0",
   "metadata": {},
   "source": [
    "Let's extract the times from the observation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2756e72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract times from EventList\n",
    "observation = observations[0]\n",
    "times = observation.events.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac8103a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93bfbeb",
   "metadata": {},
   "source": [
    "Now we have the TOAs for the events in the system of the telescope. Please note: the actual precision of the times is higher than the displayed output (and we really need this precision for the pulsar analysis!). In the next step, the timing in the SSB and the phase for each TOA has to be created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46c5d70",
   "metadata": {},
   "source": [
    "## 2.1 An ephemeris file from Fermi-LAT data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb536b7e",
   "metadata": {},
   "source": [
    "In order to compute the phases of a pulsar, one needs an ephemeris file, typically stored as a .par file.\n",
    "\n",
    "In the following, we will use an ephemeris file for the Crab provided by Fermi-LAT, see [Kerr, M.; Ray, P. S.; et al; 2015](https://arxiv.org/abs/1510.05099). This ephemeris file for the Crab pulsar can be found alongside other pulsar ephemeris files at this [confluence page]( https://confluence.slac.stanford.edu/display/GLAMCOG/LAT+Gamma-ray+Pulsar+Timing+Models). \n",
    "\n",
    "However, it is important to note that many of the ephemeris files are not up-to-date. Therefore, they could give bad results on the phase computation. In particular, you should always check that the MJD of the observations one wants to phase lies between the `START` and `FINISH` entries of the ephemeris file (see next section)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f89ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the ephemeris file\n",
    "ephemeris_file = \"0534+2200_ApJ_708_1254_2010.par\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52eb3086",
   "metadata": {},
   "source": [
    "Note that *Fermi*-LAT ephemeris files are created primarily by and for [Tempo2](https://www.pulsarastronomy.net/pulsar/software/tempo2). Most of the time, using such ephemeris file with PINT will not raise any issues. However, in a few cases, PINT does not support features from Tempo2. \n",
    "\n",
    "In our case, an error occurs when using the ephemeris file with PINT. This is due to the `JUMP` line. To proceed, simply comment  out the line (with #) or remove it. Note that this line is not important for the gamma-ray instruments, so it is acceptable to disregard it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de2d5f9",
   "metadata": {},
   "source": [
    "## 2.2 Computing pulsar phases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8ee2a8",
   "metadata": {},
   "source": [
    "Now that we have the model and the times of arrival for the different events, we can compute the timing corrections and the pulsar phases needed for the pulsar analysis. In this case, we use the PINT package described in the introduction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118886ce",
   "metadata": {},
   "source": [
    "First we will explore our model. We print some of the relevant quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24e1c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pmodels.get_model(ephemeris_file)\n",
    "print(model.components[\"AstrometryEquatorial\"])\n",
    "print(model.components[\"SolarSystemShapiro\"])\n",
    "print(model.components[\"DispersionDM\"])\n",
    "print(model.components[\"AbsPhase\"])\n",
    "print(model.components[\"Spindown\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8cd0d8",
   "metadata": {},
   "source": [
    "There are multiple parameters such as the name of the source, the frequencies of rotation and its derivatives (F0,F1,F2), the dispersion measure, etc. Check the [PINT documentation](https://nanograv-pint.readthedocs.io) for a list of additional parameters. To obtain the complete set of parameters from the ephemeris file, one can simply print the model:\n",
    "`print(model)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02f0ca5-09f2-44d4-ad76-518f8964b6a1",
   "metadata": {},
   "source": [
    "As mentioned previously, we should ensure the time of the observation lies within the ephemeris time definition. In our example, we only have one run, so we can check that manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2584b571-93a9-4fb6-b8e2-60b8810190f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Ephemeris time definition:\\n{model.START.value} - {model.FINISH.value}\"\n",
    ")\n",
    "print(\n",
    "    f\"Observation time definition:\\n{observation.tstart} - {observation.tstop}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86041174-5ec4-43ba-9035-cf567b47a3bb",
   "metadata": {},
   "source": [
    "If you have several observations that are sorted by time, you can manually check for the start time of the first observation and the stop time of the last one. Otherwise, you can create a small function like the following one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8838ee6c-5b53-4d34-8fd7-94d32daa6bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_time(observation, timing_model):\n",
    "    \"\"\"\n",
    "    Check that the observation time lies within the time definition of the pulsar\n",
    "    timing model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    observation: `gammapy.data.Observation`\n",
    "        Observation to check.\n",
    "    timing_model: `pint.models.TimingModel`\n",
    "        The timing model that will be used.\n",
    "    \"\"\"\n",
    "    model_time = Time(\n",
    "        [model.START.value, model.FINISH.value], scale=\"tt\", format=\"mjd\"\n",
    "    )\n",
    "    if (model_time[0].value > observation.tstart.tt.mjd) or (\n",
    "        model_time[1].value < observation.tstop.tt.mjd\n",
    "    ):\n",
    "        log.warning(\n",
    "            f\"Warning: Observation time of observation {observation.obs_id} goes out of timing model validity time.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d37e6cc-2cae-4192-87d9-88d52216e83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_time(observation, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a64435",
   "metadata": {},
   "source": [
    "Now we can compute the phases. For that, we define a list of TOA objects that are the main object of PINT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a145cdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Set these to True is your observatory has clock correction files.\n",
    "# If it is set to True but your observatory does not have clock correction files, it will be ignored.\n",
    "include_bipm = False\n",
    "include_gps = False\n",
    "\n",
    "# Set this to True or False depending on your ephemeris file.\n",
    "# Here we can see that the 'PLANET_SHAPIRO' entry is 'N' so we set it to True.\n",
    "planets = False\n",
    "\n",
    "# Create a TOA object for each time\n",
    "toas = toa.get_TOAs_array(\n",
    "    times=times,\n",
    "    obs=\"magic\",\n",
    "    errors=1 * u.microsecond,\n",
    "    ephem=\"DE421\",\n",
    "    include_gps=include_gps,\n",
    "    include_bipm=include_bipm,\n",
    "    planets=planets,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db97ea5b",
   "metadata": {},
   "source": [
    "Once we have the TOAs object and the model, the phases are easily computed using the model.phase() method. Note that the phases are computed in the interval [-0.5,0.5]. Most of the time, we use the phases in the interval [0,1] so we have to shift the negative ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbf3ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute phases\n",
    "phases = model.phase(toas, abs_phase=True)[1]\n",
    "\n",
    "# Shift phases to the interval (0,1]\n",
    "phases = np.where(phases < 0.0, phases + 1.0, phases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466a291e",
   "metadata": {},
   "source": [
    "## 3. Adding phases and metadata to an EventList and put it in a new Observation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edcf15f",
   "metadata": {},
   "source": [
    "Once the phases are computed we need to create a new EventList table that includes both the original information of the events and the phase information in extra columns. This is necessary for Gammapy to read the phases and use them as an extra variable of each event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735ac718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the table of the EventList\n",
    "table = observation.events.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3269a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show original table\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc6024c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column for the phases to the table\n",
    "table[\"PHASE\"] = phases.astype(\"float64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309cc644",
   "metadata": {},
   "source": [
    "Note that you can add multiple columns to a same file, only the name of the column has to be unique, eg `table['PHASE_SRC1']`, `table['PHASE_SRC2']` etc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f29187e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show table with phases\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227ab320",
   "metadata": {},
   "source": [
    "Now we can see that the 'PHASE' column has been added to the table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9ba223",
   "metadata": {},
   "source": [
    "At this point, we also want to add metadata to the table. It is very useful to keep track of what has been done to the file. For instance, if a file contains multiple pulsars, we want identify quickly which column corresponds to each pulsar. Moreover, experience has shown that it is common to have different ephemeris files for the same pulsar. Therefore, it is useful to have several phase columns in the same file to easily identify which column corresponds to each ephemeris file, parameters, etc.\n",
    "\n",
    "Since there is currently no \"standard\" format for such metadata, we propose a template for the essential information that one wants to save in the header of the event file. First, we look at the present meta info on the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af220557",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2285fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log(ephemeris_file, phase_column_name=\"PHASE\"):\n",
    "    return (\n",
    "        \"COLUMN_PHASE: \"\n",
    "        + str(phase_column_name)\n",
    "        + \"; PINT_VERS: \"\n",
    "        + pint.__version__\n",
    "        + \"; GAMMAPY_VERS: \"\n",
    "        + gammapy.__version__\n",
    "        + \"; EPHEM_FILE: \"\n",
    "        + ephemeris_file\n",
    "        + \"; PSRJ :\"\n",
    "        + str(model.PSR.value)\n",
    "        + \"; START: \"\n",
    "        + str(model.START.value)\n",
    "        + \"; FINISH: \"\n",
    "        + str(model.FINISH.value)\n",
    "        + \"; TZRMJD: \"\n",
    "        + str(model.TZRMJD.value)\n",
    "        + \"; TZRSITE: \"\n",
    "        + str(model.TZRSITE.value)\n",
    "        + \"; TZRFREQ: \"\n",
    "        + str(model.TZRFRQ.value)\n",
    "        + \"; EPHEM: \"\n",
    "        + str(model.EPHEM.value)\n",
    "        + \"; EPHEM_RA: \"\n",
    "        + str(model.RAJ.value)\n",
    "        + \"; EPHEM_DEC: \"\n",
    "        + str(model.DECJ.value)\n",
    "        + \"; PHASE_OFFSET: \"\n",
    "        + \"default = 0\"\n",
    "        + \"; DATE: \"\n",
    "        + str(Time.now().mjd)\n",
    "        + \";\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c866a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_log = get_log(ephemeris_file=ephemeris_file, phase_column_name=\"PHASE\")\n",
    "print(phase_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3e56d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the generated string to the meta data of the table\n",
    "table.meta[\"PH_LOG\"] = phase_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b44e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26592cbb",
   "metadata": {},
   "source": [
    "Once this is done, we can put back the table in a new `EventList` object and in a new `Observation` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12545bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new event list and add it to observation object\n",
    "new_event_list = EventList(table)\n",
    "new_obs = observation.copy(in_memory=True, events=new_event_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac16c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_obs.events.table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934d147a",
   "metadata": {},
   "source": [
    "## 4. Save new Event List and writing a modify HDU index table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e369d2dc",
   "metadata": {},
   "source": [
    "In the following, we show how to write the files in a directory contained in the original datastore directory. This follows the logic of DL3 data store and facilitates the manipulation of the HDU table.\n",
    "\n",
    "If you do not want to save the events files bur rather directly perform the pulsar analysis, you can skip both this step and the step of the handling metadata. However, be aware that for large datasets, the computation of the phases can take tens of minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c8410c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_store.hdu_table.base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd2ce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output directory and filename\n",
    "datastore_dir = str(data_store.hdu_table.base_dir) + \"/\"\n",
    "output_directory = \"pulsar_events_file/\"\n",
    "output_path = datastore_dir + output_directory\n",
    "filename = f\"dl3_pulsar_{observation.obs_id:04d}.fits.gz\"\n",
    "file_path = output_path + filename\n",
    "\n",
    "Path(output_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e38fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f339c797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the observation object in the specified file_path\n",
    "print(\"Writing output file in \" + str(file_path))\n",
    "new_obs.write(path=file_path, include_irfs=False, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7250c1af",
   "metadata": {},
   "source": [
    "Once the file has been written, we want to write a modified version of the HDU table. This is mandatory if we want to open the phased events file together with its associated IRFs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8dd431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the current data store HDU table.\n",
    "new_hdu = data_store.hdu_table.copy()\n",
    "new_hdu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f37e101",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in new_hdu:\n",
    "    if (entry[\"HDU_NAME\"] == \"EVENTS\") and (\n",
    "        entry[\"OBS_ID\"] == observation.obs_id\n",
    "    ):\n",
    "        entry[\"FILE_DIR\"] = \"./\" + str(output_directory)\n",
    "        entry[\"FILE_NAME\"] = filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89a7739",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_hdu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19453d2d",
   "metadata": {},
   "source": [
    "We see that the `FILE_DIR`and `FILE_NAME`entry have been modified for our phased events file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08bf493",
   "metadata": {},
   "source": [
    "Finally, we need to save the new HDU table in the original DL3 directory. One must be very careful with naming the new HDU file, such that it does not have the same name as the original HDU file of the data store. Otherwise, the original HDU file will be overwritten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1633cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_hdu.write(\n",
    "    datastore_dir + \"hdu-index-pulsar.fits.gz\", format=\"fits\", overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92cf68c",
   "metadata": {},
   "source": [
    "**Note: Here we demonstrate only one approach that could be useful, showing the steps to save the new Event files in a directory and generate a new modified HDU index table. However, the user is free to choose the absolute path of the EventList and DataStore. Another approach, for instance, could be making a full copy of the DataStore, or changing the location of the pulsar event files to one that is more convenient for the user.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfca2b8",
   "metadata": {},
   "source": [
    "## 5. Opening the new DataStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1036448",
   "metadata": {},
   "source": [
    "Once all of this is done, we just have to open the data store using DataStore.from_dir() and pass the pulsar HDU table to it :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a0e9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulsar_datastore = DataStore.from_dir(\n",
    "    DL3_dir, hdu_table_filename=\"hdu-index-pulsar.fits.gz\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c60c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = pulsar_datastore.get_observations(\n",
    "    [5029747], required_irf=\"point-like\"\n",
    ")\n",
    "observations[0].available_hdus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae8ebd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations[0].events.table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37ae9b2",
   "metadata": {},
   "source": [
    "We can see that we recover both the IRFs and the events file with the phase column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972ba493",
   "metadata": {},
   "source": [
    "## 6. Pulsar analysis tools with gammapy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe89d60",
   "metadata": {},
   "source": [
    "Once we have the correct DataStore and the modified EventList with the phase information, we can perform the pulsar analysis using different tools available in Gammapy. Allowing us to compute the phaseogram, maps, SED, lightcurve and more. To do so, please refer to the following [Gammapy tutorial](https://docs.gammapy.org/1.0/tutorials/analysis-time/pulsar_analysis.html#sphx-glr-tutorials-analysis-time-pulsar-analysis-py)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d495311",
   "metadata": {},
   "source": [
    "\n",
    "Recipe made by [Alvaros Mas](https://github.com/alvmas), [Maxime Regeard](https://github.com/MRegeard), [Jan Lukas Schubert](https://github.com/jalu98)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
